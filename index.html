<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description" content="ReAlign: Reconstruction Alignment Improves Unified Multimodal Models" />
  <meta property="og:title" content="ReAlign: Reconstruction Alignment Improves Unified Multimodal Models" />
  <meta property="og:description"
    content="Introducing ReAlign, a self-supervised training framework that aligns understanding and generation through image reconstruction at the semantic level." />
  <meta property="og:url" content="https://horizonwind2004.github.io/ReAlign-Page" />
  <meta name="twitter:title" content="ReAlign: Reconstruction Alignment Improves Unified Multimodal Models" />
  <meta name="twitter:description"
    content="Introducing ReAlign, a self-supervised training framework that aligns understanding and generation through image reconstruction at the semantic level." />
  <meta name="keywords" content="ReAlign, Vision-Language, Multimodal, Image Generation, AI, Machine Learning" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>ReAlign: Reconstruction Alignment Improves Unified Multimodal Models</title>

  <link rel="icon" type="image/png" href="static/files/teaser/logo.png">
  <link rel="shortcut icon" href="static/files/teaser/logo.png" type="image/png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/style.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>

</head>

<body>
  <!-- PDF Demo Section -->
  <section class="section" style="background-color: #f8f9fa; padding: 2rem 1rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3" style="color: #2c3e50; margin-bottom: 1rem;">ðŸ“„ Demo PDF</h2>
          <div class="content has-text-justified" style="color: #363636; margin-bottom: 2rem;">
            <p style="text-align: center; font-size: 1.1rem;">
              Explore our comprehensive demo showcasing ReAlign's capabilities and results.
            </p>
          </div>
          <div style="text-align: center; margin: 20px 0;">
            <div style="border: 2px solid #ddd; border-radius: 12px; box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1); overflow: hidden; background: white;">
              <iframe src="static/files/teaser/DEMO.pdf" 
                      style="width: 100%; height: 600px; border: none;" 
                      title="ReAlign Demo PDF">
                <p>Your browser does not support PDFs. 
                   <a href="static/files/teaser/DEMO.pdf" target="_blank" style="color: #3273dc;">Download the PDF</a>
                </p>
              </iframe>
            </div>
            <div style="margin-top: 1rem;">
              <a href="static/files/teaser/DEMO.pdf" target="_blank" 
                 class="button is-primary is-medium" 
                 style="margin-right: 1rem;">
                <span class="icon"><i class="fas fa-download"></i></span>
                <span>Download PDF</span>
              </a>
              <a href="static/files/teaser/DEMO.pdf" target="_blank" 
                 class="button is-info is-medium">
                <span class="icon"><i class="fas fa-external-link-alt"></i></span>
                <span>Open in New Tab</span>
              </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1"><img src="static/files/teaser/logo.png" style="width: 80px; height: 80px; margin-right: 20px; vertical-align: middle;" /> ReAlign: Reconstruction Alignment Improves Unified Multimodal Models</h1>
            <h2 class="subtitle is-4" style="color: #7f8c8d; margin-top: 10px;">Unlocking the Massive Zero-shot Potential in Unified Multimodal Models through Self-supervised Learning</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://horizonwind2004.github.io/" style="color: #3273dc;">Ji Xie</a><sup>1</sup>,</span>
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://people.eecs.berkeley.edu/~trevor/" style="color: #3273dc;">Trevor Darrell</a><sup>1</sup>,</span>
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://homes.cs.washington.edu/~lsz/" style="color: #3273dc;">Luke Zettlemoyer</a><sup>2</sup>,</span>
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://people.eecs.berkeley.edu/~xdwang/" style="color: #3273dc;">XuDong Wang</a><sup>1*</sup>
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block" style="color: #363636;"><sup>1</sup>UC Berkeley&nbsp;&nbsp;<sup>2</sup>University of Washington</span>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block" style="color: #363636;"><sup>*</sup>Corresponding Author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.17910" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.17910" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>ArXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/HorizonWind2004/ReAlign" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code/Models</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/collections/sanaka87/realign-68ad2176380355a3dcedc068" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">ðŸ¤—</span>
                    <span>HF Models</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/sanaka87/BAGEL-ReAlign" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">ðŸ”¥</span>
                    <span>Demo (BAGEL)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Unified multimodal models (UMMs) are designed to perform both vision understanding and image generation within a single architecture. While they have achieved strong performance on image-text understanding tasks, their generation capabilities often lag behind, revealing a misalignment between what the model understands and what it can produce. We identify this disconnect as a consequence of sparse and biased text supervision in conventional training.
            </p>
            <p>
              We propose <strong>ReAlign</strong>, a self-supervised training framework that aligns understanding and generation through image reconstruction at the semantic level. By reconstructing images from their own vision encoder embeddings, UMMs receive dense, semantically grounded supervisionâ€”free of captions or paired image-text data. This alignment mechanism effectively bridges the modality gap and improves generation fidelity.
            </p>
            <p>
              Despite its simplicity, our approach delivers strong gains for unified multimodal models across generation and editing tasks. Applied to a 1.5B parameter UMM, ReAlign achieves state-of-the-art results on GenEval (<strong>0.90</strong>) and DPGBench (<strong>88.15</strong>), outperforming models with significantly larger scale. More impressively, ReAlign achieves this with modest compute, requiring just 8,000 unlabeled images and <strong>6Ã—A100 GPUs for 4.5 hours (27 GPU-hours)</strong>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">Teaser</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign demonstrates remarkable improvements in multimodal understanding and generation capabilities through our novel reconstruction alignment approach.
            </p>
          </div>
          <div style="text-align: center; margin: 20px 0;">
            <img src="static/files/teaser/teaser.jpg" alt="ReAlign Teaser" style="width: 90%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">ReAlign: Semantic-Level Image Reconstruction</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              As shown in the figure, longer captions capture more details but still cannot fully represent the original image, missing the detailed <em><strong>overall layouts, object shapes, instance attributes, etc</strong></em>. Vision embeddings from the understanding vision encoder are already mapped into the UMM's space while retaining richer visual information. <em>Can we prompt the UMMs with embeddings from visual understanding models to close this information gap?</em>
            </p>
            <p>
              ReAlign implements a self-supervised training paradigm where a <em>understanding</em> vision encoder extracts features from the input image; these features are fused with template text embeddings and fed into a Unified Multimodal Model (UMM) to regenerate the image. We use the self-supervised loss (either diffusion loss or cross-entropy loss) between the original and generated images to optimize the UMM, providing dense supervision that preserves almost all fine-grained details that captions omit.
            </p>
          </div>
          <img src="static/files/teaser/pipeline.jpg" alt="Figure 1: ReAlign Pipeline Overview" style="width: 100%; margin: 20px 0;" />
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">State-of-the-Art Performance and Enhanced Editing Capabilities</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              After only a few training steps, all models post large <strong>zero-shot</strong> gains in generation capability with <em>no loss in vision-understanding accuracy</em>. Our fine-tuned Harmon model, even with just 1.5B parameters, achieves a high score of <strong>0.86</strong> on GenEval and <strong>87.21</strong> on DPGBench, significantly outperforming the previous state-of-the-art models <strong>without any GPT-4o-Image distillation data or reinforcement learning</strong>. The most effective approach is a <em>two-stage strategy</em>: first applying SFT followed by reconstruction tuning, which achieves <strong>0.90</strong> on GenEval and <strong>88.15</strong> on DPGBench.
            </p>
            <p>
              We surprisingly discover that, for models with <em>image editing capabilities</em>, our method also significantly improves their editing performance. ReAlign demonstrates consistent improvements across all editing categories, increasing the ImgEdit scores from 3.38 to <strong>3.75</strong> and GEdit from 6.94 to <strong>7.25</strong>, using only <em>1,000 training steps and 8,000 unlabeled images</em>. Our method unlocks the model's inherent editing potential without expensive annotation across various tasks like addition, replacement, stylization and color modification.
            </p>
          </div>
          <img src="static/files/teaser/main.jpg" alt="Table 1: Benchmark Comparison" style="width: 100%; margin: 20px 0;" />
          <img src="static/files/teaser/edit_result.jpg" alt="Image Editing Results" style="width: 100%; margin: 20px 0; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);" />

        </div>
      </div>
    </div>
  </section>

  <!-- <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">Robust Image Editing Results</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign demonstrates persistent gains in various editing tasks including addition, replacement, stylization and color modification. Our approach achieves superior performance in image editing tasks, enabling precise modifications while preserving the overall image quality and maintaining coherent visual structure. The method shows remarkable robustness against benchmark-specific overfitting compared to traditional supervised fine-tuning approaches.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section> -->

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">Enhanced Generalizability Across Different Architectures</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign achieves consistent performance gains across different UMM frameworks, showcasing its generalizability. We apply ReAlign to various unified multimodal models including Show-o (AR), Harmon (AR+MAR), OpenUni (AR+Diffusion), and BAGEL (AR+Diffusion). All models demonstrate significant improvements through ReAlign: the most notable improvement is achieved by Harmon-1.5B with 85.7 GenEval score (+12.8). Our method exhibits the most significant gains in <em>Position</em> and <em>Color Attribution</em> tasks, while maintaining correct subjects, bindings, and positions across cases with <em>multiple objects</em>, <em>complex attributions</em>, and explicit <em>spatial layouts</em>.
            </p>
          </div>
          <img src="static/files/teaser/t2i_result.jpg" alt="Text-to-Image Generation Results" style="width: 100%; margin: 20px 0; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);" />
        </div>
      </div>
    </div>
  </section>

  <!--BibTex citation -->

  <!--End BibTex citation -->

</body>

</html>
