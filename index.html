<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description" content="ReAlign: Reconstruction Alignment Improves Unified Multimodal Models" />
  <meta property="og:title" content="ReAlign: Reconstruction Alignment Improves Unified Multimodal Models" />
  <meta property="og:description"
    content="Introducing ReAlign, a self-supervised training framework that aligns understanding and generation through image reconstruction at the semantic level." />
  <meta property="og:url" content="https://horizonwind2004.github.io/ReAlign-Page" />
  <meta name="twitter:title" content="ReAlign: Reconstruction Alignment Improves Unified Multimodal Models" />
  <meta name="twitter:description"
    content="Introducing ReAlign, a self-supervised training framework that aligns understanding and generation through image reconstruction at the semantic level." />
  <meta name="keywords" content="ReAlign, Vision-Language, Multimodal, Image Generation, AI, Machine Learning" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>ReAlign: Reconstruction Alignment Improves Unified Multimodal Models</title>

  <link rel="icon" type="image/png" href="static/files/teaser/logo.png">
  <link rel="shortcut icon" href="static/files/teaser/logo.png" type="image/png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/style.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>

</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1"><img src="static/files/teaser/logo.png" style="width: 80px; height: 80px; margin-right: 20px; vertical-align: middle;" /> ReAlign: Reconstruction Alignment Improves Unified Multimodal Models</h1>
            <h2 class="subtitle is-4" style="color: #7f8c8d; margin-top: 10px;">Unlocking the Massive Zero-shot Potential in Unified Multimodal Models through Self-supervised Learning</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://horizonwind2004.github.io/" style="color: #3273dc;">Ji Xie</a><sup>1</sup>,</span>
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://people.eecs.berkeley.edu/~trevor/" style="color: #3273dc;">Trevor Darrell</a><sup>1</sup>,</span>
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://homes.cs.washington.edu/~lsz/" style="color: #3273dc;">Luke Zettlemoyer</a><sup>2</sup>,</span>
              <span class="author-block" style="color: #363636;">
                <a target="_blank" href="https://people.eecs.berkeley.edu/~xdwang/" style="color: #3273dc;">XuDong Wang</a><sup>1*</sup>
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block" style="color: #363636;"><sup>1</sup>UC Berkeley&nbsp;&nbsp;<sup>2</sup>University of Washington</span>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block" style="color: #363636;"><sup>*</sup>Corresponding Author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.17910" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.17910" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>ArXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/HorizonWind2004/ReAlign" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code/Models</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/sanaka87/BAGEL-ReAlign" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">ðŸ¤—</span>
                    <span>HF Models</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/sanaka87/BAGEL-ReAlign" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">ðŸ”¥</span>
                    <span>Demo</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Unified multimodal models (UMMs) are designed to perform both vision understanding and image generation within a single architecture. While they have achieved strong performance on image-text understanding tasks, their generation capabilities often lag behind, revealing a misalignment between what the model understands and what it can produce. We identify this disconnect as a consequence of sparse and biased text supervision in conventional training.
            </p>
            <p>
              We propose <strong>ReAlign</strong>, a self-supervised training framework that aligns understanding and generation through image reconstruction at the semantic level. By reconstructing images from their own vision encoder embeddings, UMMs receive dense, semantically grounded supervisionâ€”free of captions or paired image-text data. This alignment mechanism effectively bridges the modality gap and improves generation fidelity.
            </p>
            <p>
              Despite its simplicity, our approach delivers strong gains for unified multimodal models across generation and editing tasks. Applied to a 1.5B parameter UMM, ReAlign achieves state-of-the-art results on GenEval (<strong>0.90</strong>) and DPGBench (<strong>88.15</strong>), outperforming models with significantly larger scale. More impressively, ReAlign achieves this with modest compute, requiring just 8,000 unlabeled images and <strong>6Ã—A100 GPUs for 4.5 hours (27 GPU-hours)</strong>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">Teaser</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign demonstrates remarkable improvements in multimodal understanding and generation capabilities through our novel reconstruction alignment approach.
            </p>
          </div>
          <div style="text-align: center; margin: 20px 0;">
            <img src="static/files/teaser/teaser.jpg" alt="ReAlign Teaser" style="width: 90%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">ReAlign: Enhancing Multimodal Understanding and Generation</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign implements a self-supervised training paradigm that treats the unified multimodal model as an autoencoder. The model reconstructs images from their own vision encoder embeddings, providing dense supervision that preserves fine-grained visual details that captions often miss. This semantic-level reconstruction provides unbiased supervision that naturally aligns the model's understanding and generation capabilities without requiring any paired image-text data.
            </p>
          </div>
          <img src="static/files/teaser/pipeline.jpg" alt="Figure 1: ReAlign Pipeline Overview" style="width: 100%; margin: 20px 0;" />
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">State-of-the-Art Performance</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign achieves state-of-the-art results on GenEval (0.90) and DPGBench (88.15), outperforming models with significantly larger scale. Our 1.5B parameter model surpasses recent works like Janus-Pro, OmniGen2, and BAGEL by substantial margins while requiring minimal computational resourcesâ€”just 6Ã—A100 GPUs for 4.5 hours and 8,000 unlabeled images.
            </p>
          </div>
          <img src="static/files/comparison/gpt4o_comparison.png" alt="Table 1: Benchmark Comparison" style="width: 100%; margin: 20px 0;" />
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-4">What can ReAlign do?</h2>
          <div class="content has-text-justified" style="color: #363636;">
            <p>
              ReAlign demonstrates strong capabilities across various generation and editing tasks including stylization, object removal, object addition, and human preference editing. Our method enhances image editing quality, increasing ImgEdit scores from 3.38 to <strong>3.75</strong> and GEdit from 6.94 to <strong>7.25</strong>.
            </p>
          </div>
          <div class="video-container" style="text-align: center; margin: 20px 0;">
            <video width="80%" controls autoplay muted loop>
              <source src="static/files/teaser/teaser_medium.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!--BibTex citation -->

  <!--End BibTex citation -->

</body>

</html>
